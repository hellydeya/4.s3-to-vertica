from airflow import DAG
import logging
import vertica_python
import json
from airflow.operators.python_operator import PythonOperator
from airflow.models.variable import Variable
from datetime import datetime
from airflow.operators.trigger_dagrun import TriggerDagRunOperator
from airflow.hooks.postgres_hook import PostgresHook
from time import sleep

logging = logging.getLogger(name)

connection_pg = PostgresHook('PG_SOURCE_CONNECTION').get_conn()
connection_vertica = vertica_python.connect(**json.loads(Variable.get("VERTICA_CONNECTION")))

def sql_read_file(file_name):
with open(f'--- hello ---.sql', 'r') as sql:
return sql.read()

def wait_data(table_name, ds):
read_sql = sql_read_file('wait_data_currencies') if 'curr' in table_name else sql_read_file('wait_data_transactions')

time_sleep = 0
data_in_cursor = None
while not data_in_cursor:
    try:
        with connection_vertica.cursor() as cursor:      
            cursor.execute(read_sql.format(ds))
            if cursor.fetchone(): data_in_cursor = cursor.fetchone()[0]
    except Exception as e:
        logging.warning(f"SOMETHING WRONG! GO HARD........ EXCEPTION: {e}") 
    sleep(1)
    time_sleep += 1
    if time_sleep > 60: 
        raise ValueError('TIMEOUT....MAYBE NO DATA?!?')
def wait_data_transaction(ds):
wait_data('trans', ds)

def wait_data_currencies(ds):
wait_data('curr', ds)

def dwh_load(ds):
with connection_vertica.cursor() as cursor:
res = cursor.execute(sql_read_file("dwh_load").format(ds,ds))
logging.info(f"ON THIS DAY: {ds} RESULT ROW IS {res.fetchall()}") if res else logging.warning(f"NO DATA ON THIS DAY: {ds} GO HARD....")

with DAG(
'DAG_s3_to_dwh',
tags=['DAG_s3_to_dwh'],
start_date=datetime(2022, 10, 1),
end_date=datetime(2022, 10, 31),
schedule_interval="@daily",
max_active_runs=1,
catchup = True
) as dag:

dag_trigger = TriggerDagRunOperator(
    task_id='dag_trigger',
    trigger_dag_id='DAG_s3_to_staging',
    wait_for_completion=True,
    execution_date='{{ ds }}',
    reset_dag_run=True)

wait_data_transaction = PythonOperator(
    task_id='wait_data_transaction',
    provide_context=True,
    python_callable=wait_data_transaction)

wait_data_currencies = PythonOperator(
    task_id='wait_data_currencies',
    provide_context=True,
    python_callable=wait_data_currencies)

load_dwh = PythonOperator(
    task_id='load_dwh',
    provide_context=True,
    python_callable=dwh_load)
dag_trigger >> [wait_data_transaction, wait_data_currencies] >> load_dwh
